<!DOCTYPE html>
<html>

<head>
  <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://code.getmdl.io/1.3.0/material.indigo-pink.min.css">
  <script defer src="https://code.getmdl.io/1.3.0/material.min.js"></script>
  <style>
    #videoElement {
      width: 640px;
      height: 480px;
      border-radius: 20px;
    }
    #canvasElement {
      display: none;
      width: 640px;
      height: 480px;
    }
    .demo-content {
      padding: 20px;
      display: flex;
      flex-direction: row;
      align-items: flex-start;
      gap: 20px;
      justify-content: center;
    }
    .video-section {
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    .button-group {
      margin-bottom: 20px;
    }
    #chatLog {
      width: 400px;
      height: 560px;
      overflow-y: auto;
      border: 1px solid #ddd;
      border-radius: 8px;
      padding: 16px;
      margin-top: 0;
      background-color: #f5f5f5;
    }
    #chatLog p {
      margin: 8px 0;
      padding: 12px;
      border-radius: 8px;
      background-color: white;
      box-shadow: 0 1px 3px rgba(0,0,0,0.12);
    }
    #chatLog p:nth-child(odd) {
      background-color: #e8eaf6;
    }
  </style>
</head>

<body>
  <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header">
    <header class="mdl-layout__header">
      <div class="mdl-layout__header-row">
        <!-- Title -->
        <span class="mdl-layout-title">Gemini Live Demo</span>
      </div>
    </header>
    <main class="mdl-layout__content">
      <div class="page-content">
        <div class="demo-content">
          <div class="video-section">
            <!-- Voice Control Buttons -->
            <div class="button-group">
              <button id="startButton" class="mdl-button mdl-js-button mdl-button--fab mdl-button--mini-fab mdl-button--colored">
                <i class="material-icons">mic</i>
              </button>
              <button id="stopButton" class="mdl-button mdl-js-button mdl-button--fab mdl-button--mini-fab">
                <i class="material-icons">mic_off</i>
              </button>
            </div>
            <!-- Video Element -->
            <video id="videoElement" autoplay style="width: 640px; height: 480px;"></video>
            <!-- Hidden Canvas -->
            <canvas id="canvasElement" style="width: 640px; height: 480px;"></canvas>
          </div>
          <!-- Text Output -->
          <div id="chatLog" class="mdl-shadow--2dp"></div>
        </div>
      </div>
    </main>
  </div>

  <script defer>
    // For local testing, use ws://localhost:8000/ws; update for production
    const URL = window.location.hostname === "localhost"
      ? "ws://localhost:8080/ws"
      // : "wss://symbolic-ruperta-umarasync-6aefe9cf.koyeb.app/ws";
      : "wss://ai-tutor-456805.as.r.appspot.com/ws";

    const video = document.getElementById("videoElement");
    const canvas = document.getElementById("canvasElement");
    let context;

    window.addEventListener("load", () => {
      context = canvas.getContext("2d");
      setInterval(captureImage, 3000);
    });

    const startButton = document.getElementById('startButton');
    const stopButton = document.getElementById('stopButton');
    let stream = null;
    let currentFrameB64;
    let webSocket = null;
    let audioContext = null;
    let processor = null;
    let pcmData = [];
    let interval = null;
    let initialized = false;
    let audioInputContext;
    let workletNode;

    // Function to start screen capture
    async function startScreenShare() {
      try {
        stream = await navigator.mediaDevices.getDisplayMedia({
          video: { width: { max: 640 }, height: { max: 480 } }
        });
        video.srcObject = stream;
        await new Promise(resolve => {
          video.onloadedmetadata = () => {
            console.log("video loaded metadata");
            resolve();
          }
        });
      } catch (err) {
        console.error("Error accessing the screen: ", err);
      }
    }

    // Function to capture an image from the shared screen
    function captureImage() {
      if (stream && video.videoWidth > 0 && video.videoHeight > 0 && context) {
        canvas.width = 640;
        canvas.height = 480;
        context.drawImage(video, 0, 0, canvas.width, canvas.height);
        const imageData = canvas.toDataURL("image/jpeg").split(",")[1].trim();
        currentFrameB64 = imageData;
      } else {
        console.log("no stream or video metadata not loaded");
      }
    }

    window.addEventListener("load", async () => {
      await startScreenShare();
      await initializeAudioContext();
      connect();
    });

    function connect() {
      console.log("connecting to:", URL);
      webSocket = new WebSocket(URL);

      webSocket.onopen = (event) => {
        console.log("WebSocket open:", event);
        sendInitialSetupMessage();
      };

      webSocket.onerror = (event) => {
        console.error("WebSocket error:", event);
      };

      webSocket.onclose = (event) => {
        console.log("WebSocket closed:", event);
        alert("Connection closed");
      };

      webSocket.onmessage = receiveMessage;
    }

    function sendInitialSetupMessage() {
      console.log("sending setup message");
      const setup_client_message = {
        setup: {
          generation_config: { response_modalities: ["AUDIO"] }
        }
      };
      webSocket.send(JSON.stringify(setup_client_message));
    }

    function sendVoiceMessage(b64PCM) {
      if (!webSocket || webSocket.readyState !== WebSocket.OPEN) {
        console.log("WebSocket not initialized or not open");
        return;
      }
      const payload = {
        realtime_input: {
          media_chunks: [
            { mime_type: "audio/pcm", data: b64PCM },
            { mime_type: "image/jpeg", data: currentFrameB64 }
          ]
        }
      };
      webSocket.send(JSON.stringify(payload));
      console.log("sent payload:", payload);
    }

    function receiveMessage(event) {
      const messageData = JSON.parse(event.data);
      const response = new Response(messageData);
      if (response.text) {
        displayMessage("GEMINI: " + response.text);
      }
      if (response.audioData) {
        injestAudioChuckToPlay(response.audioData);
      }
    }

    async function initializeAudioContext() {
      if (initialized) return;
      audioInputContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
      await audioInputContext.audioWorklet.addModule("/static/pcm-processor.js");
      workletNode = new AudioWorkletNode(audioInputContext, "pcm-processor");
      workletNode.connect(audioInputContext.destination);
      initialized = true;
    }

    function base64ToArrayBuffer(base64) {
      const binaryString = window.atob(base64);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }
      return bytes.buffer;
    }

    function convertPCM16LEToFloat32(pcmData) {
      const inputArray = new Int16Array(pcmData);
      const float32Array = new Float32Array(inputArray.length);
      for (let i = 0; i < inputArray.length; i++) {
        float32Array[i] = inputArray[i] / 32768;
      }
      return float32Array;
    }

    async function injestAudioChuckToPlay(base64AudioChunk) {
      try {
        if (audioInputContext.state === "suspended") {
          await audioInputContext.resume();
        }
        const arrayBuffer = base64ToArrayBuffer(base64AudioChunk);
        const float32Data = convertPCM16LEToFloat32(arrayBuffer);
        workletNode.port.postMessage(float32Data);
      } catch (error) {
        console.error("Error processing audio chunk:", error);
      }
    }

    // Updated recordChunk function using chunking to avoid call stack overflow
    function recordChunk() {
      const buffer = new ArrayBuffer(pcmData.length * 2);
      const view = new DataView(buffer);
      pcmData.forEach((value, index) => {
        view.setInt16(index * 2, value, true);
      });

      function arrayBufferToString(buffer) {
        let binary = '';
        const bytes = new Uint8Array(buffer);
        const chunkSize = 0x8000; // 32768 bytes per chunk
        for (let i = 0; i < bytes.length; i += chunkSize) {
          binary += String.fromCharCode.apply(null, bytes.subarray(i, i + chunkSize));
        }
        return binary;
      }

      const binaryString = arrayBufferToString(buffer);
      const base64 = btoa(binaryString);
      sendVoiceMessage(base64);
      pcmData = [];
    }

    async function startAudioInput() {
      audioContext = new AudioContext({ sampleRate: 16000 });
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: { channelCount: 1, sampleRate: 16000 }
      });
      const source = audioContext.createMediaStreamSource(stream);
      processor = audioContext.createScriptProcessor(4096, 1, 1);
      processor.onaudioprocess = (e) => {
        const inputData = e.inputBuffer.getChannelData(0);
        const pcm16 = new Int16Array(inputData.length);
        for (let i = 0; i < inputData.length; i++) {
          pcm16[i] = inputData[i] * 0x7fff;
        }
        pcmData.push(...pcm16);
      };
      source.connect(processor);
      processor.connect(audioContext.destination);
      interval = setInterval(recordChunk, 3000);
    }

    function stopAudioInput() {
      if (processor) {
        processor.disconnect();
      }
      if (audioContext) {
        audioContext.close();
      }
      clearInterval(interval);
    }

    function displayMessage(message) {
      console.log(message);
      addParagraphToDiv("chatLog", message);
    }

    function addParagraphToDiv(divId, text) {
      const newParagraph = document.createElement("p");
      newParagraph.textContent = text;
      const div = document.getElementById(divId);
      div.appendChild(newParagraph);
    }

    startButton.addEventListener('click', startAudioInput);
    stopButton.addEventListener('click', stopAudioInput);

    class Response {
      constructor(data) {
        this.text = data.text || null;
        this.audioData = data.audio || null;
        this.endOfTurn = data.endOfTurn || null;
      }
    }
  </script>
</body>

</html>
